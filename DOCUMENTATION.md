# This document aims to provide an overview of the database structure and of the API to facilitate data analysis

## Introduction

The database is PostgreSQL. The choice of an SQL database vs a NoSQL one like MongoDB was made for the following main reasons:
- SQL databases enforce data integrity constraints that NoSQL databases do not, thus avoiding many programming mistakes
- storing the data in normalized form allows for a more efficient storage of the data and less resources consumption
- complex queries are efficient even on modest hardware and are easy to write (the latter point may be a matter of personal taste)

Most tables have a `created_at` and `updated_at` field, which represent the time of creation and latest update of the record.
Records are rarely updated so in most cases `updated_at` will be the same as `created_at`.

There is no timezone associated with the timestamps, they are all populated with `Date.now()` javascript calls, so UTC is assumed and the various interfaces should convert the timestamps to the user's timezone.

All records have a unique `id` field, which is an UUID generated by the database.

**Note**: in order to be able to save video data sent by the client in parallel with fetching the metadata for these videos,
the rows in the `video_metadata` do not use an `id`, they use a `youtube_id` field instead.
There is no foreign key, meaning it is not guaranteed that all videos will have metadata, but they should.

Some values are stored as enums, for storage efficiency and to enforce data correctness.

The different values of all the enum types can be listed using the following query:

```sql
select n.nspname as enum_schema,
       t.typname as enum_name,
       e.enumlabel as enum_value
from pg_type t
   inner join pg_enum e on t.oid = e.enumtypid
   inner join pg_catalog.pg_namespace n ON n.oid = t.typnamespace;
```

The database can now be accessed through the API in an easy manner, which is described after the database structure.

## Database structure

I will briefly describe each table's main fields and purpose, for more details you can explore the tables via the [web interface](https://ytdpnl-db.fmdj.fr).

### The `migrations` table

This table is not used by the business logic of the application, its purpose is to keep track of the database migrations that have been applied
so that when the schema changes in the code, the database is updated accordingly. This prevents the server code for running with a database that is not how it expects it to be.

### The `admin` table

This table contains the list of administrators of the application. It is used to grant access to the [web interface](https://personalization-server.csail.mit.edu).
The most important fields are:
- `name`
- `email`
- `password` (hashed with bcrypt, so it is not possible to retrieve the original password and the hash itself is of no value to an attacker)

### The `token` table

The [web interface](https://personalization-server.csail.mit.edu) uses a token-based authentication system (no cookies, safer). This table contains the list of tokens that have been generated by the application for administrators. A token is valid for one hour and needs to be [passed to the API](https://github.com/djfm/ytdpnl-server/blob/main/src/server-app/adminApi.ts) using the `authorization` header.

Participants do not need a token to access the API routes that they are allowed to access. The [API client](https://github.com/djfm/ytdpnl-extension/blob/main/src/api.ts) just passes the participant's code using the `x-participant-code` header.

### The `participant` table

This table contains the list of participants to the experiment.
The most important fields are:
- `code` (the code that the participants will input in the extension's setup form to identify themselves)
- `arm` (the experiment arm, either `control` or `treatment`, stored as an enum so that invalid values cannot be input)

### The `experiment_config` table

This table contains the configuration of the experiment. It is used to set the experiment's parameters.
The most important fields are:
- `comment` (a comment that can be used to describe the configuration so that admins can remember why they changed the configuration)
- `non_personalized_probability` (the probability for a participant to be displayed a video which is non-personalized)
- `is_current` (a boolean that marks whether this is the currently active configuration or not - thanks to postgres query indices, the database ensures that only one configuration is active at a time)

The web interface allows to create new configurations and never overrides the previous ones, it just sets the new configuration's `is_current` field to `true` and the previous configuration's `is_current` field to `false`.

When events are stored, the `experiment_config_id` field is populated with the `id` of the configuration that was active at the time of the event so that there is no data loss in case of a configuration update.

### The `session` table

This table represents a browsing session of a participant. It is used to tie events together.
Sessions mirror the concept of the browsers' page sessions as viewed from the point of view of the [sessionStorage](https://developer.mozilla.org/en-US/docs/Web/API/Window/sessionStorage).

A new session is created for each tab opened and ends when a tab is closed.
Duplicating a tab creates a new session.
The end of a session is not explicitly recorded in the database, it seemed unreliable to me but that can probably be added if it is useful.

The primary role of a session is to tie browsing events together.

The most important fields are:
- `uuid` (a unique identifier for the session)
- `participant_code` (the code of the participant to whom the session belongs)

To get the maximum 50 latest sessions from a participant with a given email, you can use a query like:

```sql
select *
from participant p
inner join session s on s.participant_code=p.code
where p.email='bob@example.com'
order by s.id desc
limit 50
```

to get all of them, just remove the `limit` clause.

### The `event` table

This table contains the list of events that have been recorded by the extension.
Each event is tied to a session via the `session_uuid` field.

The most important fields are:
- `session_uuid` (the uuid of the session to which the event belongs)
- `experiment_config_id` (the id of the configuration that was active at the time of the event)
- `arm` (the experiment arm, either `control` or `treatment`, stored on the event in case the participant is re-affected to a different arm later)
- `type` (the type of the event, stored as an enum)

**Note** that events are linked to sessions via the `session_uuid` field,
and not the `session_id` field, this is on purpose because session uuids are
basically random, so a malicious participant could send events for a session that
does not belong to him.

#### How the different events are stored

All events have a `type` field, following is a description of the different types of events and how they are stored.

##### `WATCH_TIME` events

The time spent watching a video, the actual time in seconds is stored in the `watch_time` table with the `event_id` field populated with the id of the event.

To get all the watch times of the latest 50 videos viewed by a given participant you can use a query like:

```sql
select p.email, e.url, e.created_at, w.seconds_watched
from participant p
inner join session s on s.participant_code=p.code
inner join event e on e.session_uuid=s.uuid and e.type='WATCH_TIME'
inner join watch_time w on w.event_id=e.id
where p.email='bob@example.com'
order by e.created_at desc
limit 50
```

The `url` field of the event contains the URL of the video that was watched.

##### `MIXED_CLICKED` events

The user clicked on a recommendation that was present in both the personalized and non-personalized recommendations.
The `url` field of the event contains the URL of the video that was clicked on.
The `context` field contains the URL of the page the user was on when the click happened.

##### `NON_PERSONALIZED_CLICKED` events

The user clicked on a recommendation that was only present in the non-personalized recommendations.
The `url` field of the event contains the URL of the video that was clicked on.
The `context` field contains the URL of the page the user was on when the click happened.


##### `PERSONALIZED_CLICKED` events

The user clicked on a recommendation that was only present in the personalized recommendations.
The `url` field of the event contains the URL of the video that was clicked on.
The `context` field contains the URL of the page the user was on when the click happened.

##### `RECOMMENDATIONS_SHOWN` events

The user was shown recommendations, the actual recommendations are stored in the `video_list_item` table with the `event_id` field populated with the id of the event.

To get the latest 50 items from the list of recommendations shown to a given participant you can use a query like:

```sql
select p.email, e.url, e.created_at, v.*, vd.*
from participant p
inner join session s on s.participant_code=p.code
inner join event e on e.session_uuid=s.uuid and e.type='RECOMMENDATIONS_SHOWN'
inner join video_list_item v on v.event_id=e.id
inner join video vd on vd.id = v.video_id
where p.email='bob@example.com'
order by e.created_at desc, v.list_type, v.position
limit 50
```

The `url` field of the event contains the URL of the page the user was on when the recommendations were shown.
The `context` field is the previous page the user was on (HTTP referrer), same as for `PAGE_VIEW` events.

##### `PAGE_VIEW` events

The user visited a page, the URL of the page is stored in the `url` field of the event.
The `context` field represents the previous page the user was on (HTTP referrer).

#### `HOME_SHOWN` events

A new kind of event has been added, its type is `HOME_SHOWN`, it serves as an identifier to which we can link the data shown on the home page of YouTube and the lists of videos, both from the homepage and from the replacement (news channel) pool.

Two new kinds of lists have been created to this effect:
- `HOME_DEFAULT` (corresponds to what would normally have been shown to the participant)
- `HOME_REPLACEMENT_SOURCE` (corresponds to the list of videos we sampled from to generate what the participant sees)

So these 2 new lists are stored in the `video_list_item` table and as usual are linked with the event that generated this list. In this case, the event is of type `HOME_SHOWN` instead of the usual `RECOMMENDATIONS_SHOWN`.

#### `HOME_INJECTED_TILE_CLICKED` events

Same properties as the `PAGE_VIEW` or `*_CLICKED` events, except it tracks only the clicks on the injected tiles on the home page.

### The `watch_time` table

This table contains the time spent watching a video.
Its fields are:
- `event_id` (the id of the event to which the watch time belongs)
- `seconds_watched` (the time spent watching the video in seconds)

### The `video_list_item` table

This table contains the lists of videos that were shown to the user.

There are two types of lists denoted by the `list_type` field:
- `NON_PERSONALIZED` (the list of videos that would have been shown to the user if they were not logged in to YouTube)
- `PERSONALIZED` (the list of videos that would have been shown to the user if they were logged in to YouTube)
- `SHOWN` (the list of videos that were actually shown to the user)

The `video_type` field represents the type of the video:
- it is always `NON_PERSONALIZED` for the `NON_PERSONALIZED` list
- it is always `PERSONALIZED` for the `PERSONALIZED` list
- it is either: `PERSONALIZED`, `NON_PERSONALIZED` or `MIXED` for the `SHOWN` list, depending on whether the video was only present in the personalized list, only present in the non-personalized list or present in both lists.

The `event_id` field represents the id of the event to which the list of videos belongs.

The `position` field represents the position of the video in the list.

Finally, the `video_id` field represents the id of the video in the `video` table, which contains basic information about the video.

### The `video` table

This table contains basic information about the videos stored in the `video_list_item` table.

Its most important fields are:
- `id` (the id of the video, used as a foreign key in the `video_list_item` table)
- `title` (the title of the video)
- `url` (the URL of the video, without the `https://www.youtube.com` prefix)
- `youtube_id` (the id of the video on YouTube)

## Some ideas to check the correctness of the data

The easiest way to perform some sanity checks on the data would probably be to make a script that first retrieves all the events for all participants in one query (without the details), ordered by session, then by event creation date:

```sql
select
p.email,
e.*,
s.created_at as session_date
from participant p
inner join session s on s.participant_code=p.code
inner join event e on e.session_uuid=s.uuid
order by s.id asc, e.created_at asc
limit 50
```

(in the script, remove the `limit` clause, I'm just including it so that the query can be tried without making the interface explode)

Then iterate over the events and perform the checks that you are interested in, using the queries that I detailed above to get the details of the events that are not fully contained in the `event` table (`WATCH_TIME` and `RECOMMENDATIONS_SHOWN`).

Please note that in general the `PAGE_VIEW` events will come right before the corresponding `RECOMMENDATIONS_SHOWN` events, but this is not guaranteed, they may be reversed because the logic that detects the page views is independent from the one that triggers the display of recommendations. The time difference between the two events should be very small in all cases. The various `*_CLICKED` events will always come after the corresponding `RECOMMENDATIONS_SHOWN` events though.

Until recently (Feb. 13, 2023) `PAGE_VIEW` events were not recorded for the first `PAGE_VIEW` of the first session of a participant, this has been fixed now. The `RECOMMENDATIONS_SHOWN` stores the same information as the `PAGE_VIEW` event on video pages though, so when analyzing the data you can just discard the `PAGE_VIEW` events on video pages and use the `RECOMMENDATIONS_SHOWN` data instead.

Another example query you might find useful is the following, it will retrieve an overview of the participants that have viewed at least 10 pages,
this can be useful to isolate the participants whose behaviour you want to analyze more closely:

```sql
select
p.id as participant_id,
p.email as participant_email,
count (distinct s.id) as n_sessions,
min(s.created_at) as first_session,
max(s.created_at) as last_session,
count(distinct pve.url) as n_pages_viewed,
count(distinct pve.url) / count(distinct s.id) as pages_per_session,
count(distinct npc.id) as n_non_personalized_clicked,
count(distinct pc.id) as n_personalized_clicked
from participant p inner join session s
  on s.participant_code=p.code
left join event pve
  on pve.session_uuid=s.uuid and pve.type='PAGE_VIEW'
left join event npc
  on npc.session_uuid=s.uuid and npc.type='NON_PERSONALIZED_CLICKED'
left join event pc
  on pc.session_uuid=s.uuid and pc.type='PERSONALIZED_CLICKED'
group by p.id
having
  count(distinct pve.url) >= 10
order by n_pages_viewed desc
```

To limit some results to those participants, you would first run that query, then add a `where` clause to your other queries like:


```sql
where p.id in (a, b, c, ..., d)
```

where `a`, `b`, `c`, ..., `d` are the `id`s of the participants you are interested in.

## API Access

In the [administration interface](https://personalization-server.csail.mit.edu) you can now generate permanent API keys in the form of JSON web tokens for easy script access to the data.

In order to access the API, first log in [to the admin panel of the experiment](https://personalization-server.csail.mit.edu) and under the "API Tokens" tab, generate a token for your application / API client.

These tokens do not expire, but you can revoke them at any time by simply deleting them.

The tokens grant the same access privileges to the API user who sends the token as to any admin user, so any call the application makes can be made
using these tokens.

To get an idea of what data is available,
you can inspect the requests made by the browser when you use the interface.

In order to authenticate with the API you just need to pass the token (the very long string of characters) as the `authorization` header of all of your HTTPS requests.

Note that you *must not* prefix the token with the string `Bearer` as is often the case in JWT-based APIs, just pass the token as is in the `authorization` header.

The 3 main endpoints you will probably want to use for data analysis are:

- `GET /api/participants/[:page]` to retrieve the list of participants
- `GET /api/participant/:email` to retrieve all of the summary data for a given participant
- `GET /api/event-overviews/:sessionUuid` to retrieve all of the events for a given session

The events retrieved by the `/api/event-overviews` endpoint are fully detailed, that is, they contain all the information that is
otherwise dispatched in the other tables for storage.

The structure of the JSON responses should be self explanatory, I will detail it if necessary.

### Create a participant through the API

You can create a participant through the API by sending a `POST` request to to `https://personalization-server.csail.mit.edu/api/participant` with the following JSON body:

```json
{
  "code": "some unique code with sufficient entropy so that no one can find a code at random",
  "arm": "either the string 'control' or 'treatment'"
  "isPaid": 1 // it needs to be a 1 to be set, the number not a letter,
              // it is optional, if it is absent or anything other than 0,
              // isPaid will be set to false in the db, and defaults to false for any new participant creation
}
```

**Note**: the `arm` field can now also be `0` (or any other value that evaluates to `false` in JavaScript, including not being specified) for `control` and `1` for `treatment`

As with all API calls, you must include a valid API token in your request, passed to the server with the `authorization` header.

The API should reply with either

```json
{
  "kind": "Success",
  "value": {...} // the participant object created
}
```

in case of success (with the HTTP status code 200),
or, in case of error:

```json
{
  "kind": "Failure",
  "message": "Some error message"
}
```

with an error HTTP status code whose exact numeric value depends on what went wrong.

An example CURL request to create a participant could be:

```bash
curl -X POST https://personalization-server.csail.mit.edu/api/participant \
 -H "Content-Type: application/json" \
 -d '{"arm": "treatment", "code": "A05SFUTF67854GHTGD236"}' \
 -H "authorization: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbklkIjoxLCJpYXQiOjE2NzY5MTkyMjIsImV4cCI6MzE3MjIxMzYxNjIyfQ.X-3ZziwMVRfDpstcSUgJlCL-Ki4mwQVL9LTddd2CnZqaly6VsjKrYd7mSgHQRn85x6wuKH2JueyFXGBEov-8z0F4XPCT9_NYLaKYccyPx3b4TO4Ww7hj5ZCvkJtb2GHe7Ho8V5uttOUxgxix0TPHYYEw90r5kQz0J2jaWhiz6NLDL3db202RCoOo_Vwgo-_PYXo0_zY5bULqCtkIBdbQqSZKWeT03QZJHSdtgsLhKJ_09w8_-daqr356CV-gKazi_uMAsW5WXPRXa5mtjgc3RxA9HW97uctLP7EunIkAjVwY3TqHxZCk87PLbiGCa-n-TCZZ6uoE49_aeAmbREG8SZTaUGNlslpHtfCsYXP48jo2wRbbHzR3wcgKaipEa3Ka6LgplW9qcIHkYqfiAvO53zrvrHJqXsBMHEbJmFm2oK87o0K9Sq5vB8d3CT8yyaysV5J06-X_0HlP3JYRan6FzyU1hht8PVbWG_wWHhwOPFXe3k8a3u5FaBm9DnpevKG4Dw4AvH3zrW-T2q89T7fpmImGTMOkIYrkNtTCMqhreWG66J24If1oww4x3h0Xreh2VOoPZbxP4jLpvIRmtNMvZxhmtNKxQXpDt8W8-gyJsovoXVOyjY5lhhcjUcjF4QpAX3TTVg5U0Jr3_2vH3mKpk6wl39_oujP-Odqf0zOOKU8"
```

(note that for obvious reasons this token is invalid, replace it with your own token)

### Update a participant through the API

Right now the only fields you can update are the `phase` and the `arm` fields.

To update a participant, send a `PUT` request to `https://personalization-server.csail.mit.edu/api/participant/:code` with a JSON body containing a subset of these fields:

```json
{
  "phase": 1 // 0 = Pre-Experiment, 1 = Experiment, 2 = Post-Experiment,
  "arm": "either the string 'control' or 'treatment'"
  "isPaid": 1 // it needs to be a 1 to be set, the number not a letter,
              // it is optional, if it is absent or anything other than 0,
              // isPaid will be set to false in the db, and defaults to false for any new participant creation
}
```
Where `:code` is the unique code identifying the participant you want to update,
and with the usual API token in the `authorization` header.

### Update the participants by CSV

You can upload a new list of participants through the UI (or API), it will update pre-existing participants and create the new ones. The upload supports the same 4 fields as the API call to create a participant, namely `code`, `arm`, `phase` and `isPaid`.

### Get the Participants Report

Always using an API token in the `authorization` header, you can get the participants report by sending a `GET` request to `https://personalization-server.csail.mit.edu/api/participants-report`.

It will return all the participants at once as a `ParticipantsReport` object, which is defined as:

```typescript
type TransitionDates = {
  entered_intervention_at: number | null;
  entered_post_intervention_at: number | null;
  was_reset_to_pre_intervention_at: number | null;
};

type ParticipantsReportRow = {
  identifier: string;
  phase: number;
  activated_browser_extension_at: number | null;
} & TransitionDates;

type ParticipantsReport = ParticipantsReportRow[];
```

The numbers in all `_at` fields are Unix timestamps in milliseconds, as given by `Date.getTime` in JavaScript.

Since there can in theory be multiple transitions for the same participant to the same phase (because they can be sent back to an earlier phase manually using the UI on the admin page or through the API),
the SQL query to construct this table is not straightforward and this call will be a bit costly, so avoid polling it too often. Once a day or even more often is fine, just don't call this 10 times per second.

When multiple transitions to the same phase are found, the timestamp of the latest transition is kept.

### Add voucher codes

You can add gift codes to the database using the following endpoint:


```bash
curl -X POST https://personalization-server.csail.mit.edu/api/voucher \
-H 'Content-Type: application/json' \
-H 'Authorization: aValidAdminToken' \
-d '["this is a code","and another one"]'
```

The codes must be passed in as a JSON array of strings in the request body.

Codes are included in the extension activation notifications.

A code can only be attributed to a participant once, this is enforced by the database.

### Channel Source Rotation Mechanism

#### Creating a Channel Source

A `Channel Source` is a list of YouTube channels that will be used to obtain the miniatures to insert on the home page.

Create them with a `POST` request to `https://personalization-server.csail.mit.edu/api/channel-source` with the following JSON body and the usual authentication token in the `authorization` header:

```json
{
  "title": "An optional title for the channel source",
  "channelIds": [
    "anyNumberOf",
    "youTubeChannelIds"
  ],
  "isDefault": true // optional, defaults to false
}
```

*Note* that the first `channel source` you create will be considered to be the default one irrespective of the `isDefault` value you pass (because we need a default).

A successful call should return something like:

```json
{
  "kind": "Success",
  "value": {
    "id": 1,
    "createdAt": "2024-01-16T14:50:14.937Z",
    "updatedAt": "2024-01-16T14:50:14.937Z",
    "isDefault": true,
    "title": "whatever title you chose"
  }
}
```

You can update a `ChannelSource` by sending the same kind of object but to `POST /api/channel-source/:id` where `:id` is the id of the channel source you want to update. The list of channels will be replaced fully with the new one (i.e. new channels are not appended to the existing ones).

There is an additional optional parameter when you update a channel source, `resetParticipantPositions`,
which is a boolean determining if participants who are affected to the channel source you are updating should have
their positions in the channel source reset to 0 or not. It defaults to false, meaning participants keep their current positions in the list.

#### Affecting a specific Channel Source to a Participant

By default, channels from the default channel source (the first one you create, or, later on, one whose `isDefault` flag you have set to true) will be used for all participants in the treatment arm.

If you want to specialize the channel source for a given participant, you can do so by sending a `PUT` request to `https://personalization-server.csail.mit.edu/api/participant/:code` where `:code` is the participant's code and send a JSON object containing at least:

```json
{
  "channelSourceId": 2 // the id of the channel source you want to affect to the participant
}
```

The id of the channel source is given in the `value` field of the response you obtain when you create a channel source via API, as illustrated by the example in the previous point.

You can also update the position of the participant in the list of channels that is affected to them using the same route but sending a JSON object containing at least:

```json
{
  "posInChannelSource": 12 // the position of the channel in the list of channels that is affected to the participant
}
```

Both operations can be performed at the same time by sending a JSON object containing both fields, this is just the regular participant update route.

Note that the latter option is not supported in the participant creation route, because it is assumed that a participant newly created starts at the first position in the channel source (which is 0, not 1).

#### Setting the rotation speed of channels in the absence of clicks

Simply send an authenticated `POST` request to `/api/channel-rotation-speed` with a JSON body containing:

```json
{
  "speedHours": 12 // the number of hours after which channel sources should be rotated
}
```

This setting is never overwritten, a history of all the changes is kept in the database. When no entry is present for this setting in the database the duration defaults to 24 hours.

**Note**: `speedHours` doesn't have to be an integer, it can be any number.

#### Getting the current channel rotation speed setting

Send an authorized `GET` request to `/api/channel-rotation-speed`, it will return a JSON object containing something like:

```json
{
  "kind": "Success",
  "value": {
    "id": 1,
    "speedHours": 12,
    "createdAt": "2024-01-16T14:50:14.937Z",
    "updatedAt": "2024-01-16T14:50:14.937Z"
  }
}
```

#### Miscellaneous

Channels that are deemed unusable by the extension will be saved in the table `unusable_channel`.
